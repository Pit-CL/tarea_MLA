# -*- coding: utf-8 -*-
"""Tarea MLA_Rafael_Farias.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15FXKxmwfR5Ni8Yu-T7Ya0B_F9_5DrbXv

# Librerías Necesarias.
"""

# Importamos las librerías necesarias.
import pandas as pd
from fbprophet import Prophet
from fbprophet.plot import add_changepoints_to_plot
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from numpy import asarray
from pandas import read_csv
from pandas import DataFrame
from pandas import concat
from sklearn.metrics import mean_absolute_error
from xgboost import XGBRegressor
from matplotlib import pyplot
from fbprophet.diagnostics import performance_metrics, cross_validation
from fbprophet.plot import plot_cross_validation_metric
import itertools
import numpy as np
import seaborn as sns
import random
random.seed(1234)

"""# IO"""

# Abrimos el archivo.

file_path = '/home/rafaelfarias/Dropbox/Postgrados/MDS/MLA/Tarea MLA/data/Tarea MLA - Hoja 2.csv'
df = pd.read_csv(file_path)

# Le doy formato a la fecha para poder trabajarla.
df['ds'] = pd.to_datetime(df['ds'], format='%d/%m/%Y')
df = df.sort_values(by=['ds'], ascending=True)
df.reset_index(drop=True, inplace=True)

# Guardo el df ordenado para usarlo en el pronóstico del modelo mejor.
df.to_csv(r'/home/rafaelfarias/Dropbox/Postgrados/MDS/MLA/Tarea MLA/data/datos2.csv',
          index=False)

path2 = '/content/drive/MyDrive/MDS/MLA/datos2.csv'

"""# Estadística descriptiva."""

# Graficamos los datos.
graf = sns.histplot(data=df, kde='true')
plt.show()

outliers = sns.boxplot(data=df['y'])
plt.show()

# Describo los datos.
df.describe()

"""# Prophet."""

# Le indicamos al modelos los días "importantes"
dias_especiales = pd.DataFrame({
    'holiday': 'dias_especiales',
    'ds': pd.to_datetime(['2018-02-14', '2019-02-14', '2020-02-14',
                          '2021-02-14', '2022-02-14'], format='%Y-%m-%d'),
    'lower_window': -1,
    'upper_window': 1,
})
holidays = dias_especiales

"""## Modelo"""

# Creamos el modelo Prophet y le hacemos un fit.
m = Prophet(holidays=holidays, weekly_seasonality=True, daily_seasonality=False,
            yearly_seasonality=False, n_changepoints=10)
m.add_country_holidays(country_name='Chile')
m.fit(df)

# Se indica cuáles serán los futures.
future = m.make_future_dataframe(periods=7)
future.tail()

"""### Forecast"""

# Forecast
forecast = m.predict(future)
forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(14)

"""### Gráficos componentes del Forecast."""

# Se grafican los componentes del forecast (trend, weekly, yearly)
fig2 = m.plot_components(forecast)
plt.show()

"""### Gráfico con los Changepoints"""

# Se grafica cuándo se producen los mayores cambios en la tendencia.
fig3 = m.plot(forecast)
a = add_changepoints_to_plot(fig3.gca(), m, forecast)
plt.show()

"""### Crossvalidation."""

# Crossvalidation.
df_cv = cross_validation(m, initial='30 days', horizon='7 days',
                         parallel='processes', period='1 days')

df_p = performance_metrics(df_cv, rolling_window=1)

fig4 = plot_cross_validation_metric(df_cv, metric='mae')
plt.show()

print('MAE de Prophet: %.3f' % df_p['mae'])

"""## Hiperparámetros."""

# Ahora pruebo varios hiperparámetros para correr el modelo denuevo y
# compararlo.
param_grid = {
    'changepoint_prior_scale': [0.4, 0.5],

    'seasonality_prior_scale': [0.001, 0.01, 0.1, 0.5, 1, 5, 10],

    'holidays_prior_scale': [0.001, 0.01, 0.1, 0.5, 1, 5, 10]
}

# Generate all combinations of parameters
all_params = [dict(zip(param_grid.keys(), v))
              for v in itertools.product(*param_grid.values())]
maes = []  # Store the maes for each params here

# Use cross validation to evaluate all parameters
for params in all_params:
    m = Prophet(**params, yearly_seasonality=False, daily_seasonality=False, weekly_seasonality=True,
                holidays=holidays, n_changepoints=10)
    m.add_country_holidays(country_name='Chile')
    m.fit(df)  # Fit model with given params
    df_cv = cross_validation(m, initial='30 days', horizon='7 days',
                             parallel='processes', period='1 days')
    df_p = performance_metrics(df_cv, rolling_window=1)
    maes.append(df_p['mae'].values[0])

# Find the best parameters
tuning_results = pd.DataFrame(all_params)
tuning_results['mae'] = maes

# Se imprime el mejor parámetro.
best_params = all_params[np.argmin(maes)]
best_params
# Darle index para lograr automatizar el paso de más abajo

"""## Modelo 2"""

# Creamos el modelo Prophet con el nuevo hiperparámetro 0.5 y 0.9 y
# le hacemos un fit.
m2 = Prophet(changepoint_prior_scale=0.5, changepoint_range=0.9,
             weekly_seasonality=True, holidays=holidays, yearly_seasonality=False, daily_seasonality=False,
             n_changepoints=10)
m2.add_country_holidays(country_name='Chile')
m2.fit(df)

# Se indica cuáles serán los futures y el período hacia adelante.
future2 = m2.make_future_dataframe(periods=7)
future2.tail()

"""### Forecast."""

# Forecast
forecast2 = m2.predict(future2)
forecast2[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(14)

"""### Gráficos componentes del Forecast."""

forecast2[['yhat_upper']].sum()

# Se grafican los componentes del forecast (trend, weekly, yearly)
fig6 = m2.plot_components(forecast2)
plt.show()

"""### Gráfico con los Changepoints."""

# Se grafica cuándo se producen los mayores cambios en la tendencia.
fig7 = m2.plot(forecast2)
a2 = add_changepoints_to_plot(fig7.gca(), m2, forecast2)
plt.show()

"""### Crossvalidation."""

# Crossvalidation
df_cv2 = cross_validation(m2, initial='30 days', horizon='7 days',
                          parallel='processes', period='1 days')

df_p2 = performance_metrics(df_cv2, rolling_window=1)

fig8 = plot_cross_validation_metric(df_cv2, metric='mae')
plt.show()

print('MAE de Prophet: %.3f' % df_p2['mae'])

"""# XGBoost."""

###############################################################################
# XGBoost.
###############################################################################
m2 = XGBRegressor()


# transform a time series dataset into a supervised learning dataset
def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):
    n_vars = 1 if type(data) is list else data.shape[1]
    df = DataFrame(data)
    cols = list()
    # input sequence (t-n, ... t-1)
    for i in range(n_in, 0, -1):
        cols.append(df.shift(i))
    # forecast sequence (t, t+1, ... t+n)
    for i in range(0, n_out):
        cols.append(df.shift(-i))
    # put it all together
    agg = concat(cols, axis=1)
    # drop rows with NaN values
    if dropnan:
        agg.dropna(inplace=True)
    return agg.values


# split a univariate dataset into train/test sets
def train_test_split(data, n_test):
    return data[:-n_test, :], data[-n_test:, :]


# fit an xgboost model and make a one step prediction
def xgboost_forecast(train, testX):
    # transform list into array
    train = asarray(train)
    # split into input and output columns
    trainX, trainy = train[:, :-1], train[:, -1]
    # fit model
    model = XGBRegressor(objective='reg:squarederror', n_estimators=3000,
                         max_depth=20, booster='gbtree')
    model.fit(trainX, trainy)
    # make a one-step prediction
    yhat = model.predict(asarray([testX]))
    return yhat[0]


# walk-forward validation for univariate data
def walk_forward_validation(data, n_test):
    predictions = list()
    # split dataset
    train, test = train_test_split(data, n_test)
    # seed history with training dataset
    history = [x for x in train]
    # step over each time-step in the test set
    for i in range(len(test)):
        # split test row into input and output columns
        testX, testy = test[i, :-1], test[i, -1]
        # fit model on history and make a prediction
        yhat = xgboost_forecast(history, testX)
        # store forecast in list of predictions
        predictions.append(yhat)
        # add actual observation to history for the next loop
        history.append(test[i])
        # summarize progress
        print('>expected=%.1f, predicted=%.1f' % (testy, yhat))
    # estimate prediction error
    error = mean_absolute_error(test[:, -1], predictions)
    return error, test[:, -1], predictions


# forecast monthly selling with xgboost

# load the dataset
series = read_csv(path2, header=0, index_col=0)
values = series.values

# transform the time series data into supervised learning
data = series_to_supervised(values, n_in=6)

# evaluate
mae, y, yhat = walk_forward_validation(data, 30)

# plot expected vs predicted
pyplot.plot(y, label='Expected')
pyplot.plot(yhat, label='Predicted')
pyplot.legend()
pyplot.show()

# Pronosticando próximo día tomando en cuenta los 10 días anteriores.
# load the dataset
series = read_csv(path2, header=0, index_col=0)
values = series.values

# transform the time series data into supervised learning
train = series_to_supervised(values, n_in=30)

# split into input and output columns
trainX, trainy = train[:, :-1], train[:, -1]

# fit model
model = XGBRegressor(objective='reg:squarederror', n_estimators=3000,
                     max_depth=20, booster='gbtree')

model.fit(trainX, trainy)

# construct an input for a new prediction
row = values[-30:].flatten()

# make a one-step prediction
yhat = model.predict(asarray([row]))
print('Input: %s, Predicted with XGBoost: %.3f' % (row, yhat[0]))

print('MAE de Prophet 1: %.3f' % df_p['mae'])
print('MAE de Prophet 2: %.3f' % df_p2['mae'])
print('MAE de XGBoost 2: %.3f' % mae)

